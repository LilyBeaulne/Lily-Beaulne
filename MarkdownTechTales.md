# *PHIL 3370 Reflection*
## Tech Tales: Using AI Wisely
*March 2025*

Lily Beaulne
### Summary
> This is the summary of this project that i will write soon. here is its relevence to our hournal. i do not plan to submit it to our journal
### Process

I chose to create a children's book concept with Microsoft Co-pilot. Co-pilot did a good job  with concept planning, suggesting multiple characters, themes, and situations to explore.
The initial interaction seemed the most cohesive and helpful, It was a good starting point and gave me a lot to work with and refine.
I didn’t like the initial name of the AI Co-pilot suggested, Zippy, so I used it to brainstorm some other ideas. 
These name ideas fell flat for the most part, but Buddy seemed the most appropriate for the story.
I questioned why Zippy was chosen first, and Co-pilot was able to give sound justification, mentioning it being energetic and relating to AI through this sense of efficiency. 
I let Co-pilot know that Buddy would be the name of the AI moving forward.
I also wanted to pivot from the first title suggested, as it wasn’t very education-oriented. 
Co-pilot suggested ten new ideas, each treating Buddy as a human character; you wouldn’t know it’s an AI from these titles. 
So, I further clarified that it should be clear that Buddy is an AI system. 
This prompt would be used multiple times throughout our interactions as Co-pilot tended to drift from this concept. 
I landed on a title that doesn’t focus on the characters, as even with this clarification, the titles were still too unclear- that's how we ended up with **Tech Tales: Using AI Wisely**.
The rest of our interactions focused on creating visuals and book pages for this story using the designer interface of Co-pilot.
We started with the concept art of Ava and Buddy, which once again initially completely ignored the fact that Buddy is an AI system. 
After another reminder, Co-pilot was able to create a visual that depicted Buddy in a more accurate light, but still very personified in a more sci-fi robot figure. 

I’d also like to note that even though we were dealing with the same character, Ava, in all the visuals, Co-pilot more often than not changed how she looked completely.
After these few initial concepts, I prompted for the art style to be storybook-esque. 
The first cover, though aesthetically pleasing, still ignored many previous prompts about Buddy not being an actual robot, and instead being a tablet program- Ava's appearance also changed again.
The next cover iterations, after clarification of Buddy’s nature, were much better, and we eventually ended up with a cover that I am really happy with.
I ran into the most challenges when it came to visuals depicting actual story content, including dialogue.
I first started this part with a prompt for a sample comic that depicted one of the lessons from the story planning.
This yielded a nice comic, with Buddy on a tablet, but it lacked actual story content. 
This is where I let Co-pilot choose what story to focus on, creating a plan for a four-panel comic. C
o-pilot came up with one for online safety, with a short line of dialogue from Ava and Buddy in each panel.
Co-pilot struggled with integrating all the parts of this plan into the visuals, once again running into the problem of personifying Buddy.
Our chat was cut short by the response limit for a single chat shortly after. 


### Technical Understanding
The greatest limitation I faced when using Co-pilot for this project was its *lack of memory*. 
Co-pilot was not doing a great job of remembering both inputs and outputs from previous interactions.
This inhibited certain parts of the creative process, as I would have to take the time to remind Co-pilot of previous decisions we had made.
This mainly included Ava’s appearance, as well as how Buddy was to be presented in the visuals. 
Ava was initially depicted as a young Black girl, but her race, age, and other factors frequently changed. 
I even received a visual with a grown woman as Ava.
As for Buddy, Co-pilot had a hard time not personifying him, at least to a small degree. 
Buddy was regularly shown as a classic sci-fi robot, like a kid's toy. 
This probably comes from the usual depictions of very high-level AI robots in modern media, which Co-pilot would train itself on.
I think Co-pilot had a hard time with having a non-physical figure be a ‘character’ in the book, as it's not too typical in books, especially kids' books.

To try and get around these challenges, I would repeat previous prompts and include previous outputs in some of the new interactions to make sure that Co-pilot knew where its starting point was.
The last trouble I ran into during our interactions to make storybook pages was that of text. 
The Co-pilot designer is not good at including text in its images, most likely due to insufficient training.
There would be correct words, but many would be misspelled or depicted by weird symbols.
Despite these challenges, Co-pilot did a good job in the quality of the visuals for the most part, especially on the cover ideas. 
I think the wording of my prompt here helped, as I made sure to include the title of our story as well as links to storybooks in general, giving Co-pilot the direction to take inspiration from illustrated storybooks and their typical features.
As AI progresses, I expect that these challenges will become minimal to none.
With better ‘memory’ and ‘trains of thought’, Co-pilot will be able to make better outputs that consider not only the larger context of our interactions but also the specific previous actions.
As time goes on, AI image creation may be better at creating things that they don’t have a concrete reference for, like Buddy being a program on a tablet and not a physical being. 

### Ethical Implications

The use of Co-pilot to create this children's story raised several ethical considerations.
I found myself thinking mainly about the division of labor (specialization) and the role of AI in creative fields.
Co-pilot was great at providing the broader structure to the story, as well as simple dialogue, but ultimately failed to create great visuals for this project.
When it comes to specialization, where we delegate tasks between humans and AI based on who excels at them, AI probably shouldn't be given the creative visual tasks for the storybook. 
Humans are able to draw more abstract ideas; even Buddy being a program on a tablet seemed too much for Co-pilot to handle.
So, humans may be better at the ‘simpler’ seeming task here of illustration, but it still proves a challenge for Co-pilot. 
Co-pilot is better at the writing component, which is still creative.
I think that Co-pilot would have much more training data for this aspect of the process than that of the visual components, making it better at writing and producing consistently good outputs.

While AI is better at the broader structures, humans remain better at the more nuanced, though possibly less complex, tasks. 
I think this consideration calls for a relationship between Co-pilot and its human user where the AI takes on the larger-scale creative planning, and the human contributes the more specific illustrations and refinement of story ideas and emotions.
Concerns about ethical misconduct on my end arose as well.
When reminding Co-pilot that Buddy should be a program helping Ava through the tablet in the visuals, I was met with a potential conduct violation. 
I was unable to further investigate this due to a lack of transparency on their end.
This reflects the ‘black box’ nature of AI, especially deep learning systems, where decisions can remain opaque. 
I was able to receive justification for previous simpler decisions, but when it came to this misconduct, I was met with no justification. 
So how am I able to make sure I am acting within their ethical conduct expectations? 

I feel like AI cannot truly push the boundaries of existing creative expression due to some of these factors.
It relies on training data and existing patterns, rather than human imaginative capabilities.
Though they may not be pushing the boundaries, many may find it satisfactory enough. 
Existing story writers and illustrators may face displacement by AI, but I don’t believe this will happen on a large scale—at least for a while.
AI has a lot of catching up to do to match the creative and abstract abilities of the human mind. 
I find that AI may start to chip away at the human desire to create emotion and connect through art.
When we start to see art as instantly being able to be created, it takes away from its impact—we even see this with human artists.
Finally, in the context of children's stories, I feel children may suffer from AI art becoming a prominent mode for books. 
These stories and illustrations may lack the authentic emotional content and human experience that these storybooks are meant to invoke to teach children.
This makes me question the impact of AI-driven storytelling on young people, and how these effects will change as AI increases its capabilities 
